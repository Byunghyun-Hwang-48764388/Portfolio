ğŸ“Œ Project Overview
- Built a production-level data pipeline on Databricks using PySpark to analyze diabetes risks. The core focus was implementing a scalable Medallion Architecture to ensure data reliability and structured processing for large-scale healthcare datasets.

ğŸ› ï¸ Tech Stack
- Engine: Apache Spark (PySpark)
- Environment: Databricks
- Architecture: Medallion Architecture (Bronze, Silver, Gold Layers)

ğŸ—ï¸ Data Engineering Milestones
- Bronze Layer: Ingested raw healthcare records into a landing zone, preserving original data integrity.
- Silver Layer: Performed schema enforcement, missing value imputation, and data cleaning using PySpark to create a "source of truth."
- Gold Layer: Optimized feature-engineered tables specifically for ML training, implementing business-level aggregations.
- Scalable Pipeline: Designed the entire flow to be scalable within a distributed cloud environment.

ğŸ–¥ï¸ Presentation
- Full Engineering Report: Detailed folder structures, pipeline diagrams, and ML results are in the uploaded PPT/PDF. Please refer to the documentation in this repository.
